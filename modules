/*
Containers can be extracted from different sources
https://github.com/nf-core/tools/issues/1291
conda: https://www.nextflow.io/docs/latest/conda.html
singularity: https://depot.galaxyproject.org/singularity/
docker: https://quay.io/organization/biocontainers
*/

/**************************************************************************************************************************************************************
* fastQC
**************************************************************************************************************************************************************/

process fastqc {	
     errorStrategy { sleep(Math.pow(2, task.attempt) * 200 as long); return 'retry' }
    maxRetries 3

	publishDir "${params.outdir}/fastqc",
        mode: params.publish_intermediate_files 
	
	//use container
    conda (params.enable_conda ? "bioconda::fastqc" : null)
    if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) {
        container "https://depot.galaxyproject.org/singularity/fastqc%3A0.12.1--hdfd78af_0"
    } else {
        container "quay.io/biocontainers/fastqc:0.11.9--0"
    }

    input:
        tuple val(prefix), path (reads) 
	
	output:
        tuple val(prefix), path("*.html"), emit: html
        tuple val(prefix), path("*.zip") , emit: zip
        path  "*details.txt"          , emit: version
        //path "*.log" , emit: fastqc_log


    script:
        software = "${params.software_versions}"
        """
        cmd="fastqc ${reads}"
        echo "version"  >> ${software}
        fastqc --version >> ${software}
        echo "version" >>  ${software}
     
        echo "\${cmd}" >>  ${software}
      
        \${cmd}
        """
}


/**************************************************************************************************************************************************************
* trimmomatic
**************************************************************************************************************************************************************/


process trimmomatic {
     errorStrategy { sleep(Math.pow(2, task.attempt) * 200 as long); return 'retry' }
    maxRetries 3

	publishDir "${params.outdir}/trimmomatic",
        mode: params.publish_intermediate_files 

	//use container
    conda (params.enable_conda ? "bioconda::trimmomatic" : null)
    if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) {
        container "https://depot.galaxyproject.org/singularity/trimmomatic:0.39--hdfd78af_2"
    } else {
        container "quay.io/biocontainers/trimmomatic"
    }

    input:
        tuple val(prefix), path (reads) 

    output:
        tuple val(prefix), path("*.trim.fastq")   , emit: trimmed_reads
        tuple val(prefix), path("*.unpaired.trim*"),  optional:true, emit: unpaired_reads
        path  "*details.txt"          , emit: version
        path ".*log" , emit: trimmomatic_log



    script:
        software = "${params.software_versions}"
        fq_1_paired = prefix +'.R1.trim.fastq'
        fq_1_unpaired = prefix +'.R1.unpaired.trim.fastq'
        fq_2_paired = prefix +'.R2.trim.fastq'
        fq_2_unpaired = prefix +'.R2.unpaired.trim.fastq'
        adapter="${params.adapter_file}"

        """
        wget -O ${adapter} https://raw.githubusercontent.com/usadellab/Trimmomatic/main/adapters/${adapter}

        cmd="trimmomatic \
            PE -phred33 \
            ${reads[0]} \
            ${reads[1]} \
            $fq_1_paired \
            $fq_1_unpaired \
            $fq_2_paired \
            $fq_2_unpaired \
            ILLUMINACLIP:${adapter}:2:30:10"

        echo  -n 'trimmomatic '  >> ${software}
        echo "version" >>  ${software}
        trimmomatic -version >> ${software}
        echo "version" >>  ${software}
        echo "\${cmd}" >>  ${software}
        \${cmd}
        """
}

/**************************************************************************************************************************************************************
* unicycler
**************************************************************************************************************************************************************/

process unicycler_short {
    errorStrategy { sleep(Math.pow(2, task.attempt) * 200 as long); return 'retry' }
    maxRetries 3

	publishDir "${params.outdir}/unicycler",
        mode: params.publish_intermediate_files 

	//use container
    conda (params.enable_conda ? "python=3.7 bioconda::unicycler" : null)
    if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) {
        container "https://depot.galaxyproject.org/singularity/unicycler:0.5.0--py39h4e691d4_3"
    } else {
        container "quay.io/biocontainers/unicycler"
    }

    input:
        tuple val(prefix), path (reads) 

    output:
        tuple val(prefix), path("${prefix}/assembly.fasta"), emit: scaffolds
        tuple val(prefix), path("${prefix}/assembly.gfa"), emit: gfa
        tuple val(prefix), path("${prefix}"), emit: scaffolds_path
        path  "*details.txt"          , emit: version
        path ".*.log" , emit: unicycler_log


    script:
        software = "${params.software_versions}"
        task.cpus="${params.threads}"
        """
        cmd="unicycler --threads ${task.cpus} -1 ${reads[0]} -2  ${reads[2]} --out ${prefix}" 

        echo "version" >>  ${software}
        unicycler --version >> ${software}
        echo "version" >>  ${software}
        echo "\${cmd}" >>  ${software}
  
        \${cmd}
        """
}

/**************************************************************************************************************************************************************
* busco
**************************************************************************************************************************************************************/

process busco {
     errorStrategy { sleep(Math.pow(2, task.attempt) * 200 as long); return 'retry' }
    maxRetries 3


	publishDir "${params.outdir}/busco",
        mode: params.publish_intermediate_files 

	//use container
    conda (params.enable_conda ? "bioconda::busco" : null)
    if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) {
        container "https://depot.galaxyproject.org/singularity/busco%3A5.5.0--pyhdfd78af_0"
    } else {
        container "quay.io/biocontainers/busco"
    }
    input:
        val scaffolds

    output:
        path "assembly_qc/*.txt", emit: summary_file
        val outdir, emit:species_outdir
        path  "*details.txt"          , emit: version
        path ".*.log" , emit: busco_log

    script:
        task.cpus="${params.threads}"
        software = "${params.software_versions}"
        busco_dataset="${params.lineage}"
        """
        cmd="busco -f -i ${scaffolds} -o assembly_qc --mode genome -l ${busco_dataset} -c ${task.cpus}" 
        echo "\${cmd}" >>  ${software}
        busco --version
        \${cmd}
        """
    }

/**************************************************************************************************************************************************************
* checkm 
**************************************************************************************************************************************************************/


process checkm {

 errorStrategy { sleep(Math.pow(2, task.attempt) * 200 as long); return 'retry' }
    maxRetries 3

	publishDir "${params.outdir}/checkm",
        mode: params.publish_intermediate_files 

//use container
    conda (params.enable_conda ? "bioconda::checkm-genome" : null)
    if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) {
        container "https://depot.galaxyproject.org/singularity/checkm-genome%3A1.2.2--pyhdfd78af_1"
    } else {
        container "quay.io/biocontainers/checkm-genome"
    }

    input:
        tuple val(prefix), path (scaffolds_path)
         
    output:
        tuple val(prefix), path("${prefix}.tsv")  , emit: checkm_tsv
        path  "*details.txt"   , emit: version
        path ".*.log" , emit: checkm_log


    script:
        task.cpus="${params.threads}"
        software = "${params.software_versions}"
        fasta_ext = 'fasta'
        """
        cmd="checkm  lineage_wf  -t $task.cpus  -f ${prefix}.tsv  --tab_table  --pplacer_threads $task.cpus  -x $fasta_ext  $scaffolds_path  ${prefix}_output" 
        
        \${cmd}

        echo "version" >>  ${software}
        checkm 2>&1 | grep '...:::' | sed 's/.*CheckM v//;s/ .*//'  >>  ${software}
        echo "version" >>  ${software}
        echo "\${cmd}" >>  ${software}
        """
}

/**************************************************************************************************************************************************************
* checkV
**************************************************************************************************************************************************************/

process db_checkv_download {
    label 'mount_local_scripts'
    
    errorStrategy { sleep(Math.pow(2, task.attempt) * 200 as long); return 'retry' }
    maxRetries 3

	storeDir "${baseDir}/DB/db_checkv"

	//publishDir "${params.outdir}/DB/db_checkv",
      //  mode: params.publish_intermediate_files 

//use container
    conda (params.enable_conda ? "python=3.7 bioconda::checkv" : null)
    if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) {
        container "https://depot.galaxyproject.org/singularity/checkv%3A1.0.1--pyhdfd78af_0"
    } else {
        container "quay.io/biocontainers/checkv"
    }
         
    output:
        path ("checkv-db*"), emit: checkvdb

    script:
        task.cpus="${params.threads}"
        software="${params.software_versions}"
        """
        chmod a+x /ProkGenomics_scripts/db_checkv.sh
        checkv download_database ./ || /ProkGenomics_scripts/db_checkv.sh
 
        """
}





process checkv {
    label 'mount_local_scripts'
    
    errorStrategy { sleep(Math.pow(2, task.attempt) * 200 as long); return 'retry' }
    maxRetries 3

	publishDir "${params.outdir}/checkv",
        mode: params.publish_intermediate_files 

//use container
    conda (params.enable_conda ? "python=3.7 bioconda::checkv" : null)
    if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) {
        container "https://depot.galaxyproject.org/singularity/checkv%3A1.0.1--pyhdfd78af_0"
    } else {
        container "quay.io/biocontainers/checkv"
    }

    input:
        tuple val(prefix), path (scaffolds)
         
    output:
        tuple val(prefix), path("${prefix}/quality_summary.tsv"), emit: checkv_summary
        tuple val(prefix), path("${prefix}/completeness.tsv"), emit: checkv_completeness
        tuple val(prefix), path("${prefix}/contamination.tsv"), emit: checkv_contamination
        tuple val(prefix), path("${prefix}/complete_genomes.tsv"), emit: checkv_genomes
        tuple val(prefix), path("${prefix}/viruses.fna"), emit: checkv_viruses_fna
        tuple val(prefix), path("${prefix}/proviruses.fna"), emit: checkv_proviruses_fna
        path  "*details.txt"          , emit: version
        path ".*.log" , emit: checkv_log

    script:
        task.cpus="${params.threads}"
        software="${params.software_versions}"
        checkv_database="${baseDir}/DB/db_checkv/checkv-db*"
        """
        cmd="checkv end_to_end ${scaffolds} ${prefix} -t ${task.cpus} -d ${checkv_database}" 
        echo "\${cmd}" >>  ${software}
        
        \${cmd}
        
        echo "version" >>  ${software}
        checkv |head -1| sed 's/: assessing the quality of metagenome-assembled viral genomes//' >>  ${software}
        echo "version" >>  ${software}
        
        echo "\${cmd}" >>  ${software}


        """
}


/**************************************************************************************************************************************************************
* plasclass
**************************************************************************************************************************************************************/

process plasclass {
    errorStrategy { sleep(Math.pow(2, task.attempt) * 200 as long); return 'retry' }
    maxRetries 3
    //errorStrategy 'ignore'

	publishDir "${params.outdir}/plasclass",
        mode: params.publish_intermediate_files 

    conda (params.enable_conda ? "python=3.7 bioconda::plasclass": null)
    if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) {
        container "https://depot.galaxyproject.org/singularity/plasclass%3A0.1.1--pyhdfd78af_0"
    } else {
        container "quay.io/biocontainers/plasclass"
    }

    input:
        tuple val(prefix), file(scaffolds)

    output:
        tuple val(prefix), path ("${prefix}.probs.out") , emit: plasclass_tsv
        path  "*details.txt" , emit: version
        path ".*.log" , emit: plasclass_log

    script:
        task.cpus="${params.threads}"
        software="${params.software_versions}"
        
        """
        
        cmd="classify_fasta.py -f ${scaffolds} -p ${task.cpus} -o ${prefix}.probs.out"
        \${cmd}

        echo "version" >>  ${software}
        echo "plasclass 0.1.1" ${software}
        echo "version" >>  ${software}

        echo "\${cmd}" >>  ${software}

        """

}

/**************************************************************************************************************************************************************
* prokka
**************************************************************************************************************************************************************/


process prokka {
     errorStrategy { sleep(Math.pow(2, task.attempt) * 200 as long); return 'retry' }
    maxRetries 3

	publishDir "${params.outdir}/prokka",
        mode: params.publish_intermediate_files 

//use container
    conda (params.enable_conda ? "bioconda::prokka" : null)
    if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) {
        container "https://depot.galaxyproject.org/singularity/prokka%3A1.14.6--pl5321hdfd78af_5"
    } else {
        container "quay.io/biocontainers/prokka"
    }

    input:
        tuple val(prefix), file(contigs_bacteria)
        val (element)

    output:
        tuple val(prefix), path ("${prefix}_${element}_prokka_annotation") , emit: prokka_path
        path  "*details.txt" , emit: version
        path ".*.log" , emit: prokka_log

    script:
        task.cpus="${params.threads}"
        software = "${params.software_versions}"
        """
        cmd="prokka --outdir ${prefix}_${element}_prokka_annotation --prefix ${prefix} --cpus ${task.cpus} ${contigs_bacteria}"
        \${cmd}
  
        echo "version" >>  ${software}
        prokka --version >> ${software}
        echo "version" >>  ${software}
        echo "\${cmd}" >>  ${software}

        """

}


/**************************************************************************************************************************************************************
* pharokka
**************************************************************************************************************************************************************/


process db_pharokka_download {
       label 'mount_local_scripts'

     errorStrategy { sleep(Math.pow(2, task.attempt) * 200 as long); return 'retry' }
    maxRetries 3

	storeDir "${baseDir}/DB/db_pharokka"

//use container
    conda (params.enable_conda ? "bioconda::pharokka" : null)
    if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) {
        container "https://depot.galaxyproject.org/singularity/pharokka%3A1.5.1--pyhdfd78af_0"
    } else {
        container "quay.io/biocontainers/pharokka"
    }


    output:
        path("pharokka_databases"), emit: pharokkadb

    script:
        task.cpus="${params.threads}"
        software = "${params.software_versions}"
        """

        chmod a+x /ProkGenomics_scripts/db_pharokka.sh
        install_databases.py -o pharokka_databases || /ProkGenomics_scripts/db_pharokka.sh
       
        """

}



process pharokka {
       label 'mount_local_scripts'

     errorStrategy { sleep(Math.pow(2, task.attempt) * 200 as long); return 'retry' }
    maxRetries 3

	publishDir "${params.outdir}/pharokka",
        mode: params.publish_intermediate_files 

//use container
    conda (params.enable_conda ? "bioconda::pharokka" : null)
    if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) {
        container "https://depot.galaxyproject.org/singularity/pharokka%3A1.5.1--pyhdfd78af_0"
    } else {
        container "quay.io/biocontainers/pharokka"
    }

    input:
        tuple val(prefix), file(contigs_phage)

    output:
        tuple val(prefix), path ("${prefix}_phage_pharokka_annotation"), emit: pharokka_path, optional: true
        path  "*details.txt" , emit: version, optional: true
        path ".*.log" , emit: pharokka_log, optional: true

    script:
        task.cpus="${params.threads}"
        software = "${params.software_versions}"
        pharokka_databases = "${baseDir}/DB/db_pharokka/pharokka_databases"
        """
        cmd="pharokka.py -i ${contigs_phage} -o ${prefix}_phage_pharokka_annotation -d ${pharokka_databases} -t ${task.cpus} -f"
        cmd_meta="pharokka.py -i ${contigs_phage} -o ${prefix}_phage_pharokka_annotation -d ${pharokka_databases} -t ${task.cpus} -meta -f"

        checkcontignum=` grep ">" ${contigs_phage} | wc -l `

        if [  \$checkcontignum -gt 1 ]; then \$cmd_meta; else \$cmd; fi

        echo "version" >>  ${software}
        pharokka.py --version >> ${software}
        echo "version" >>  ${software}


        echo "\${cmd}" >>  ${software}


        """

}




/**************************************************************************************************************************************************************
* snippy
**************************************************************************************************************************************************************/


process snippy {
     errorStrategy { sleep(Math.pow(2, task.attempt) * 200 as long); return 'retry' }
    maxRetries 3

	publishDir "${params.outdir}/snippy",
        mode: params.publish_intermediate_files 

//use container
    conda (params.enable_conda ? "bioconda::snippy" : null)
    if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) {
        container "https://depot.galaxyproject.org/singularity/snippy%3A4.6.0--hdfd78af_3"
    } else {
        container "quay.io/biocontainers/snippy"
    }

    input:
        tuple val(prefix_genome), path (reference_genome)
        tuple val(prefix), path (trimmed_reads)

    output:
        tuple val(prefix), path ("${prefix}_${prefix_genome}_snippy/snps.vcf"), emit: snippy_path
        path  "*details.txt" , emit: version
        path ".*.log" , emit: snippy_log

    script:
        task.cpus="${params.threads}"
        software = "${params.software_versions}"
    

    """
    echo "again"
    cmd="snippy --cpus ${task.cpus} --outdir ${prefix}_${prefix_genome}_snippy --ref ${reference_genome} --R1 ${trimmed_reads[0]} --R2 ${trimmed_reads[2]}"

    \${cmd}

    echo "version" >>  ${software}
    snippy --version >> ${software}
    echo "version" >>  ${software}

    echo "\${cmd}" >>  ${software} 

    """

}

/**************************************************************************************************************************************************************
* GTDBTK
**************************************************************************************************************************************************************/

process db_gtdb_download {

    label 'mount_local_scripts'
    
     //errorStrategy { sleep(Math.pow(2, task.attempt) * 200 as long); return 'retry' }
    //maxRetries 3
    storeDir "${baseDir}/DB/db_gtdb"
	//publishDir "${baseDir}/db_gtdb",
      //  mode: params.publish_db_folder

    conda (params.enable_conda ? "bioconda::gtdbtk" : null)
    if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) {
        container "https://depot.galaxyproject.org/singularity/gtdbtk%3A2.3.2--pyhdfd78af_0"
    } else {
        container "quay.io/biocontainers/gtdbtk"
    }
    
    output:
        path ("rele*"),  emit: gtdbtk_db_path
        env (db_diskspace), emit: db_diskspace
        path (".command.env"), emit: db_diskspace_command

    script:   
    db_existing="${params.db_gtdb_path}"
    """
    spacedisk=`df -k ./ | awk '\$NF == "/" { if(\$5 == "/") print \$3; else print \$4 }'`
    db_size=1048576
    db_existing="${db_existing}"

    
    if [ ! -d ${db_existing} ]
     then  
      if [ "\$spacedisk" -lt "\$db_size"  ]
        then
         echo "first condition"
            db_diskspace="Skipped! No space for gtdb database!"
        else
            echo "second condition"
            chmod a+x /ProkGenomics_scripts/db_gtdb.sh
            download-db.sh || /ProkGenomics_scripts/db_gtdb.sh
            db_diskspace="done"
        fi
     else
       echo "third condition"
       # ln -s ${db_existing} 
        db_diskspace="done" 
    fi

    """

}



process gtdb {

    label 'mount_local_scripts'
    
	publishDir "${params.outdir}/GTDB",
        mode: params.publish_intermediate_files 

    conda (params.enable_conda ? "bioconda::gtdbtk" : null)
    if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) {
        container "https://depot.galaxyproject.org/singularity/gtdbtk%3A2.3.2--pyhdfd78af_0"
    } else {
        container "quay.io/biocontainers/gtdbtk"
    }


    input:
        tuple val(prefix), path (chromosome_path)
        path ( gtdbtk_db_path)
        path (db_diskspace_command)

    output:
        tuple val(prefix), path("${prefix}_gtdbtk_classification/gtdbtk.${prefix}*.summary.tsv")         , emit: gtdbtk_summary, optional: true
        tuple val(prefix), path("${prefix}_gtdbtk_classification/gtdbtk.${prefix}*.classify.tree.gz")    , emit: gtdbtk_tree, optional: true
        tuple val(prefix), path("${prefix}_gtdbtk_classification/gtdbtk.${prefix}*.markers_summary.tsv") , emit: gtdbtk_markers, optional: true
        tuple val(prefix), path("${prefix}_gtdbtk_classification/gtdbtk.${prefix}*.msa.fasta.gz")        , emit: gtdbtk_msa, optional: true
        tuple val(prefix), path("${prefix}_gtdbtk_classification/gtdbtk.${prefix}*.user_msa.fasta.gz")   , emit: gtdbtk_user_msa, optional: true
        tuple val(prefix), path("${prefix}_gtdbtk_classification/gtdbtk.${prefix}*.filtered.tsv")        , emit: gtdbtk_filtered, optional: true
        tuple val(prefix), path("${prefix}_gtdbtk_classification/gtdbtk.${prefix}*.failed_genomes.tsv")  , emit: gtdbtk_failed, optional: true
        tuple val(prefix), path("${prefix}_gtdbtk_classification/gtdbtk.warnings.log")          , emit: gtdbtk_warnings, optional: true
        path  "*details.txt" , emit: version, optional: true
        path ".*.log" , emit: gtdbtk_log, optional: true
   
    script:
    task.cpus="${params.threads}"
    software = "${params.software_versions}"
   
    """
    echo ""
    mkdir chromosome
    fullpath=`readlink -f ${chromosome_path}`
    ln -s \$fullpath chromosome/${chromosome_path}
    source ${db_diskspace_command}
    echo \$db_diskspace
    if [ \$db_diskspace = "done" ]; 
        then
            export GTDBTK_DATA_PATH="${gtdbtk_db_path}"
            echo \$GTDBTK_DATA_PATH
            echo \$db_diskspace
            cmd="gtdbtk classify_wf --genome_dir chromosome/ --prefix gtdbtk.${prefix} --out_dir ${prefix}_gtdbtk_classification --cpus ${task.cpus} --skip_ani_screen --extension fasta"

            echo "version" >>  ${software} 
            gtdbtk --version| sed 's/Copyright 2017 Pierre-Alain Chaumeil, Aaron Mussig and Donovan Parks//' >> ${software}
            echo "version\n\n" >>  ${software}

            echo "\${cmd}" >>  ${software} 
             \${cmd} || touch ${prefix}_gtdbtk_classification/gtdbtk.${prefix}.summary.tsv
             #add --gtdbtk_pplacer_scratch
        else
            echo "classification failed. Need more disk space" 
    fi
    
    """

}

/**************************************************************************************************************************************************************
* split assembly
**************************************************************************************************************************************************************/

        
process split_assembly {
	publishDir "${params.outdir}/splitting_assemblies",
        mode: params.publish_intermediate_files 

  conda (params.enable_conda ? "bioconda::samtools" : null)
    if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) {
        container "https://depot.galaxyproject.org/singularity/samtools%3A1.9--h91753b0_8"
    } else {
        container "quay.io/biocontainers/samtools"
    }


    input:
        tuple val(prefix), path (scaffolds_path)
        tuple val(prefix), path (plasclass_tsv)
        tuple val(prefix), path (checkv_summary)
    
    output:
        tuple val(prefix), path("${prefix}_de_novoassembly.fasta"), emit: novoassembly_path, optional: true
        tuple val(prefix), path("${prefix}_chromosome.fasta"), emit: chromosome_path, optional: true
        tuple val(prefix), path("${prefix}_plasmid.fasta"), emit: plasmid_path, optional: true
        tuple val(prefix), path("${prefix}_phage.fasta"), emit: phage_path, optional: true
        
    script:

        """
        # all contigs 
        grep ">" ${scaffolds_path} |cut -d " " -f1|sed 's/>//' >all_contigs.txt

        #plasmid contigs
        awk 'BEGIN{OFS="\\t"} \$2 >= 0.8 {print \$1}' ${plasclass_tsv} >plasmid_contigs.txt

        #phage contigs
        grep "Yes" ${checkv_summary}| cut -f1 >phage_contigs.txt

        #extrachr contigs
        cat plasmid_contigs.txt phage_contigs.txt >extrachr.txt
        
        #chromosome contigs
        grep -vwf extrachr.txt all_contigs.txt >chromosome_contigs.txt

        #extract contigs
        if [ -s chromosome_contigs.txt ]; then xargs samtools faidx ${scaffolds_path} < chromosome_contigs.txt > ${prefix}_chromosome.fasta; fi
        if [ -s plasmid_contigs.txt ]; then xargs samtools faidx ${scaffolds_path} < plasmid_contigs.txt > ${prefix}_plasmid.fasta; fi
        if [ -s phage_contigs.txt ]; then xargs samtools faidx ${scaffolds_path} < phage_contigs.txt > ${prefix}_tmp_phage.fasta; fi
        if [ -s ${prefix}_tmp_phage.fasta ]; then awk 'BEGIN { FS=OFS=" " } /^>/ { print \$1"_phage"; next }1' ${prefix}_tmp_phage.fasta > ${prefix}_phage.fasta; fi

        ln -s ${scaffolds_path} ${prefix}_de_novoassembly.fasta

        """



}


/**************************************************************************************************************************************************************
* Prodigal
**************************************************************************************************************************************************************/
process prodigal {
     errorStrategy { sleep(Math.pow(2, task.attempt) * 200 as long); return 'retry' }
    maxRetries 3

  	publishDir "${params.outdir}/prodigal",
        mode: params.publish_intermediate_files 

  conda (params.enable_conda ? "bioconda::prodigal" : null)
    if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) {
        container "https://depot.galaxyproject.org/singularity/prodigal%3A2.60--1"
    } else {
        container "quay.io/biocontainers/prodigal"
    }

    input:
    tuple val(prefix), path(contigs)
    val(seq)


    output:
    tuple val(prefix), path("${prefix}_${seq}_genes.gff"), emit: gene_annotations
    tuple val(prefix), path("${prefix}_${seq}_genes.fasta"), emit: nucleotide_fasta
    tuple val(prefix), path("${prefix}_${seq}_genes.faa"), emit: amino_acid_fasta
    path  "*details.txt" , emit: version
    path ".*.log" , emit: prodigal_log 


    script:
    task.cpus="${params.threads}"
    software = "${params.software_versions}"
 
    """
    
    cmd="prodigal -i ${contigs}  -o ${prefix}_${seq}_genes.gff -a ${prefix}_${seq}_genes.faa -d ${prefix}_${seq}_genes.fasta -f gff -q -p meta"

    \${cmd}

    echo "version" >>  ${software}
    prodigal -v 2>&1 | sed -n 's/Prodigal V\\(.*\\):.*/\\1/p' >> ${software}
    echo "version" >>  ${software}

    echo "\${cmd}" >>  ${software} 

    """
}

/**************************************************************************************************************************************************************
* modify reference
**************************************************************************************************************************************************************/


process reference_format {

    label 'bash_var_zro_one'
    
    errorStrategy { sleep(Math.pow(2, task.attempt) * 200 as long); return 'retry' }
    maxRetries 3

  	publishDir "${params.outdir}/minimap2",
        mode: params.publish_intermediate_files 

  conda (params.enable_conda ? "anaconda::biopython" : null)
    if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) {
        container "https://depot.galaxyproject.org/singularity/biopython%3A1.81"
    } else {
        container "quay.io/biocontainers/biopython"
    }

   input:
        tuple val(prefix_genome), path (reference_genome)

    output:
        tuple val(prefix_genome), path("${prefix_genome}_ready.fasta"), emit: reference_genome_ready

    script:
        task.cpus="${params.threads}"
        software = "${params.software_versions}"
        """
        # this was a funny error. because process.shell = ['/bin/bash', '-euo', 'pipefail'] when the variable is 1 it thinks it is a error (exit 1) 
        # check the reference genome format
        
        checkformat=\$(head -1 ${reference_genome}| grep "LOCUS"| wc -l)
        if [ \$checkformat -eq 0 ]; then FILEFORMAT='fasta' ; else FILEFORMAT='gbk'; fi

        if [ \$FILEFORMAT == 'gbk' ]; then python -c "from Bio import SeqIO; SeqIO.convert(\'${reference_genome}\', 'genbank',\'${prefix_genome}_ready.fasta\', 'fasta')"; else cp ${reference_genome} ${prefix_genome}_ready.fasta; fi
        
        """
}





/**************************************************************************************************************************************************************
* minimap2
**************************************************************************************************************************************************************/
// 

process minimap2 {
   // label 'mount_bash_basics'
     errorStrategy { sleep(Math.pow(2, task.attempt) * 200 as long); return 'retry' }
    maxRetries 3

	publishDir "${params.outdir}/minimap2",
        mode: params.publish_intermediate_files 

//use container
    conda (params.enable_conda ? "bioconda::minimap2" : null)
    if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) {
        container "https://depot.galaxyproject.org/singularity/minimap2%3A2.9--1"
    } else {
        container "quay.io/biocontainers/minimap2"
    }

    input:
        tuple val(prefix_genome), path (reference_genome_ready)
        tuple val(prefix), path (trimmed_reads)

    output:
        tuple val (prefix), path ("${prefix}_${prefix_genome}_map.sam"), emit: minimap2_path
        path  "*details.txt" , emit: version
        path ".*.log" , emit: minimap2_log

    script:
        task.cpus="${params.threads}"
        software = "${params.software_versions}"
        
        """
        minimap2 -ax sr ${prefix_genome}_ready.fasta ${trimmed_reads[0]} ${trimmed_reads[2]} > ${prefix}_${prefix_genome}_map.sam
        

        echo "version" >>  ${software}
        minimap2 --version >> ${software}
        echo "version" >>  ${software}
        
        """

}

/**************************************************************************************************************************************************************
* get coverage
**************************************************************************************************************************************************************/

process get_coverage {
    errorStrategy { sleep(Math.pow(2, task.attempt) * 200 as long); return 'retry' }
    maxRetries 3
	
    publishDir "${params.outdir}/minimap2",
        mode: params.publish_intermediate_files 

  conda (params.enable_conda ? "bioconda::samtools" : null)
    if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) {
        container "https://depot.galaxyproject.org/singularity/samtools%3A1.9--h91753b0_8"
    } else {
        container "quay.io/biocontainers/samtools"
    }
    input:
        tuple val(prefix), path(mapped)

    output:
        tuple val (prefix), path ("${prefix}_coverage_stast.txt"), emit: stats_path
        tuple val (prefix), path ("${prefix}_sorted.bam"), emit: sorted_path


    script:
        task.cpus="${params.threads}"
        software = "${params.software_versions}"
        
        """
        samtools sort  ${mapped} -o ${prefix}_sorted.bam
        samtools flagstat ${prefix}_sorted.bam > ${prefix}_coverage_stast.txt
        
        """

}

/**************************************************************************************************************************************************************
* qualimap
**************************************************************************************************************************************************************/

process qualimap {
    errorStrategy { sleep(Math.pow(2, task.attempt) * 200 as long); return 'retry' }
    maxRetries 3

    publishDir "${params.outdir}/qualimap",
        mode: params.publish_intermediate_files 

  conda (params.enable_conda ? "bioconda::qualimap" : null)
    if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) {
        container "https://depot.galaxyproject.org/singularity/qualimap%3A2.3--hdfd78af_0"
    } else {
        container "quay.io/biocontainers/qualimap"
    }

    input:
        tuple val(prefix), path(mapped)

    output:
        tuple val (prefix), path ("${prefix}_qualimap_results"), emit: qualimap_results

    script:
        task.cpus="${params.threads}"
        software = "${params.software_versions}"
    
    """ 
    qualimap bamqc -bam ${mapped} -outdir ${prefix}_qualimap_results
    """ 
}


/**************************************************************************************************************************************************************
* clinker
**************************************************************************************************************************************************************/
// https://depot.galaxyproject.org/singularity/clinker%3A1.33--hdfd78af_0
// if reference genome is gbk then runs clinker


/**************************************************************************************************************************************************************
* blast database
**************************************************************************************************************************************************************/
// 

process makeblastdb {
    errorStrategy { sleep(Math.pow(2, task.attempt) * 200 as long); return 'retry' }
    maxRetries 3

    storeDir "${params.genes_interest}"
    //publishDir "${params.outdir}/blast",
    //    mode: params.publish_intermediate_files 

  conda (params.enable_conda ? "bioconda::blast" : null)
    if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) {
        container "https://depot.galaxyproject.org/singularity/blast%3A2.9.0--pl526he19e7b1_7"
    } else {
        container "quay.io/biocontainers/blast"
    }

    input:
        tuple val (prefix), path (genes_fasta)

    output:
        tuple val (prefix),path ("${prefix}.*"), emit: blastDB
  
    script:
    genes_type="nucl"
    """
    makeblastdb -dbtype ${genes_type} -in ${genes_fasta} -out ${prefix}
    """
}

process blast{
    errorStrategy { sleep(Math.pow(2, task.attempt) * 200 as long); return 'retry' }
    maxRetries 3

    
    publishDir "${params.outdir}/blast",
        mode: params.publish_intermediate_files 

  conda (params.enable_conda ? "bioconda::blast" : null)
    if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) {
        container "https://depot.galaxyproject.org/singularity/blast%3A2.9.0--pl526he19e7b1_7"
    } else {
        container "quay.io/biocontainers/blast"
    }

    input:
        tuple val (prefix0), path (sequence)
        tuple val (prefix1), path (gene_id)
        val (percentage) 
        

    output:
        tuple val (prefix0),path ("${prefix0}_${prefix1}.Blast.txt"), emit: blast_output
  
    script:

    """
    blastn -query ${sequence} -db ${prefix1} -dust no -outfmt "6 qseqid sseqid pident qlen slen length qstart qend sstart send mismatch gapope evalue bitscore" -perc_identity ${percentage} -out ${prefix0}_${prefix1}.Blast.txt

    """
}




/*
process blast {
    input:
    path 'query.fa'
    path db

    output:
    path 'top_hits'

    """
    blastp -db $db/$db_name -query query.fa -outfmt 6 > blast_result
    cat blast_result | head -n 10 | cut -f 2 > top_hits
    """
}
*/

/**************************************************************************************************************************************************************
* Assembly2Gene
**************************************************************************************************************************************************************/
// 


process Assembly2Gene{
    label 'mount_local_scripts'
    errorStrategy { sleep(Math.pow(2, task.attempt) * 200 as long); return 'retry' }
    maxRetries 3

    publishDir "${params.outdir}/blast",
        mode: params.publish_intermediate_files 

  conda (params.enable_conda ? "" : null)
    if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) {
        container "https://github.com/MonashBioinformaticsPlatform/containers/pkgs/container/containers%2Ffromassembly2feature"
    } else {
        container ""
    }

    input:
        tuple val (prefix0), path (sequence)
        tuple val (prefix1), path (blast_output)
        tuple val (prefix2), path (gene_fasta)
        tuple val (prefix3), path (gene_id)

    output:
        tuple val (prefix0),path ("${prefix0}_${prefix1}.Blast.txt"), emit: blast_output
  
    script:

    """
    cut -f 1 ${sequence} > ${sequence}_temp
    xargs samtools faidx ${sequence}} < ${sequence}_temp > ${sequence}_temp_seqs
	cat ${gene_fasta}; cat ${sequence}_temp_seqs > ${sequence}_${gene_fasta}_temp_seqs";
	Rscript /ProkGenomics_scripts/curatingAlignments_nt.r  ${sequence}_${gene_fasta}_temp_seqs ${gene_id} ${sequence}_${gene_fasta}_alignment.fasta ${sequence}_${gene_fasta}_alignment_description

    """
}





//				system("xargs samtools faidx $genes_fasta_chr < $temp_chr >$output_gene_chr");


/*
   # awk '/^>/ {printf(\"\\n\%s\\n\",\$0);next; } { printf(\"\%s\",\$0);}  END {printf(\"\\n\");}' < ${sequence}_temp_seqs > ${sequence}_temp_seqs.tmp";	

	my $temp_chr=$output_alignments_chr."/".$gene_tag.".tmp";
			system("cut -f 1 $outputblast_chr >$temp_chr");
			my $output_gene_chr= $output_alignments_chr."/".$gene_tag.".fasta";
			if( $genes_type eq 'nucl'){
				system("xargs samtools faidx $genes_fasta_chr < $temp_chr >$output_gene_chr");
			}elsif($genes_type eq 'prot'){
				system("xargs samtools faidx $genes_faa_chr < $temp_chr >$output_gene_chr");


				system($cmd_awk);
				system("mv $output_gene_chr.tmp $output_gene_chr");
				system("rm $temp_chr");
				my $output_ref_chr=$output_gene_chr.".plusRef.fasta";
				system($cmd);
				my $out_alignment_description=$dirresults."/".$genome.".".$gene_tag.".chr.out.alignments.description";
				open OUT, ">$out_alignment_description" or die "Cannot open $out_alignment_description for writing\n";
				my $gene_genome_chr_out_alignment_AA_fasta=$dirresultspep."/".$gene_tag."_".$genome.".chr.AAsequence.fasta";
				open OUT1, ">$gene_genome_chr_out_alignment_AA_fasta" or die "Cannot open $gene_genome_chr_out_alignment_AA_fasta for writing\n";
				my $gene_genome_chr_out_alignment_nt_fasta=$dirresults."/".$gene_tag."_".$genome.".chr_alignment.fasta.tmp";
				open OUT2, ">$gene_genome_chr_out_alignment_nt_fasta" or die "Cannot open  $gene_genome_chr_out_alignment_nt_fasta for writing\n";
				my $rcmd=" Rscript $results_folder/scripts/curatingAlignments.r  $output_ref_chr $gene_tag $gene_genome_chr_out_alignment_nt_fasta $gene_genome_chr_out_alignment_AA_fasta $out_alignment_description --slave";
				print "-------$rcmd-------\n\n";
				system($rcmd);
*/

//my $cmd_blast_chr="blastn -query $genes_fasta_chr -db $gene_id -dust no -outfmt \"6 qseqid sseqid pident qlen slen length qstart qend sstart send mismatch gapope evalue bitscore\" -perc_identity $percentage -out $outputblast_chr";



/**************************************************************************************************************************************************************
* Report
**************************************************************************************************************************************************************/



process report{
    label 'mount_local_scripts'

    publishDir "${params.outdir}",
        //mode: params.publish_dir_mode 
        mode: params.publish_intermediate_files 

    //errorStrategy 'ignore'
      conda (params.enable_conda ? "r-base r-rmarkdown" : null)
    if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) {
        container "rocker/tidyverse"
        //container "https://depot.galaxyproject.org/singularity/r-rmarkdown%3A0.9.5--0"
        //// container "https://depot.galaxyproject.org/singularity/r-markdown%3A0.8--r3.4.1_1"
    } else {
        container "quay.io/biocontainers/R"
    }

    input:
        val (prefix)
        tuple val(prefix0), path (fastqc_html)
        tuple val(prefix1), path (fastqc_trim_html)
        tuple val(prefix2), path (novoassembly_path)
        tuple val(prefix3), path (chromosome_path)
        tuple val(prefix4), path (plasmid_path)
        tuple val(prefix5), path (phage_path)
        tuple val(prefix6), path (checkm_tsv)
        tuple val(prefix7), path (prokka_denovo_path)
        tuple val(prefix8), path (prokka_chr_path)
        tuple val(prefix9), path (prokka_plasmid_path)
        tuple val(prefix10), path (pharokka_path)
        tuple val(prefix11), path (plasmid_class)
        tuple val(prefix12), path (phage_class)
        tuple val(prefix13), path (snippy_path)
        tuple val(prefix14), path (qualimap_path)
        tuple val(prefix16), path (stats_path)
        tuple val(prefix15), path (gtdbtk_summary)
        //

        //tuple val(prefix), path (assembly2gene_table)
        //tuple val(prefix), path (assembly2gene_aligments)
        //tuple val(prefix), path (assembly2gene_peptides)

    output:
        tuple val(prefix), path("${prefix}_ProkGenomics_report.html"), emit: report_path

    script:
        task.cpus="${params.threads}"
        software= "${params.software_versions}"
        version= "${params.version}"
        github="${params.github}"
        report_template="${params.report_template}"
        Rrender="${params.Rrender}"

        """          
        echo "again"
        echo "Run Rscript in one line in the container"  
        Rscript /ProkGenomics_scripts/report_render.R  "/ProkGenomics_scripts/report.Rmd"\\
            ${params.outdir}\\
            ${prefix} ${version}\\
            ${github}\\
            ${params.outdir}/fastqc/${fastqc_html[0]}\\
            ${params.outdir}/fastqc/${fastqc_html[1]}\\
            ${params.outdir}/fastqc/${fastqc_trim_html[0]}\\
            ${params.outdir}/fastqc/${fastqc_trim_html[2]}\\
            ${params.outdir}/unicycler/${novoassembly_path}\\
            ${params.outdir}/splitting_assemblies/${chromosome_path}\\
            ${params.outdir}/splitting_assemblies/${plasmid_path}\\
            ${params.outdir}/splitting_assemblies/${phage_path}\\
            ${params.outdir}/checkm/${checkm_tsv}\\
            ${params.outdir}/prokka/${prokka_denovo_path}\\
            ${params.outdir}/prokka/${prokka_chr_path}\\
            ${params.outdir}/prokka/${prokka_plasmid_path}\\
            ${params.outdir}/pharokka/${pharokka_path}\\
            ${params.outdir}/plasclass/${plasmid_class}\\
            ${params.outdir}/checkv/${phage_class}\\
            ${params.outdir}/snippy/${snippy_path}\\
            ${params.outdir}/qualimap/${qualimap_path}\\
            ${params.outdir}/minimap2/${stats_path}\\
            ${params.outdir}/GTDB/${prefix15}_gtdbtk_classification/${gtdbtk_summary}
            
                                  
        """



}



/**************************************************************************************************************************************************************
* multiqc
**************************************************************************************************************************************************************/

process multiqc {
    errorStrategy { sleep(Math.pow(2, task.attempt) * 200 as long); return 'retry' }
    maxRetries 3

    publishDir "${params.outdir}/multiqc",
        mode: params.publish_intermediate_files 

  conda (params.enable_conda ? "bioconda::multiqc" : null)
    if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) {
        container "https://depot.galaxyproject.org/singularity/multiqc%3A1.9--pyh9f0ad1d_0"
    } else {
        container "quay.io/biocontainers/multiqc"
    }

    input:
        tuple val(prefix), path (folder_fastqc)
        tuple val(prefix), path (folder_mapping)
 
    output:
        tuple val (prefix), path("multiqc_report.html"), emit: multiqc_report
        tuple val (prefix), path("multiqc_data/"), emit: multiqc_data
      
    """
    multiqc .
    """
}






// check the version 
//sed -n '/version/, /version/{ /version/!p }' software_details.txt 

process cleanup{
    input:
    tuple val(prefix), path(report_path)  //here I gave the input from last process.

    script:
    """
    echo "rm -rf $PWD/work/*"
    echo "rm -rf $PWD/.nextflow.log*"
    """
}